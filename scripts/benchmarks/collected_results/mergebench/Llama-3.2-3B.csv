model,task_category,task_name,metric_name,score
meta-llama/Llama-3.2-3B,math,gsm8k_cot,"exact_match,flexible-extract",0.3070507960576194
meta-llama/Llama-3.2-3B,multilingual,m_mmlu_fr,"acc,none",0.45802459705140935
meta-llama/Llama-3.2-3B,multilingual,arc_fr,"acc_norm,none",0.38922155688622756
meta-llama/Llama-3.2-3B,multilingual,hellaswag_fr,"acc_norm,none",0.5757121439280359
meta-llama/Llama-3.2-3B,multilingual,m_mmlu_es,"acc,none",0.47000149992500373
meta-llama/Llama-3.2-3B,multilingual,arc_es,"acc_norm,none",0.37777777777777777
meta-llama/Llama-3.2-3B,multilingual,hellaswag_es,"acc_norm,none",0.5916364412203968
meta-llama/Llama-3.2-3B,multilingual,m_mmlu_de,"acc,none",0.45376376527379697
meta-llama/Llama-3.2-3B,multilingual,arc_de,"acc_norm,none",0.3592814371257485
meta-llama/Llama-3.2-3B,multilingual,hellaswag_de,"acc_norm,none",0.5349060631938514
meta-llama/Llama-3.2-3B,multilingual,m_mmlu_ru,"acc,none",0.42615514722841547
meta-llama/Llama-3.2-3B,multilingual,arc_ru,"acc_norm,none",0.3455945252352438
meta-llama/Llama-3.2-3B,multilingual,hellaswag_ru,"acc_norm,none",0.5159620362381363
meta-llama/Llama-3.2-3B,instruction_following,ifeval,"inst_level_loose_acc,none",0.17985611510791366
meta-llama/Llama-3.2-3B,coding,mbpp_plus,"pass_at_1,none",0.5396825396825397
meta-llama/Llama-3.2-3B,coding,humaneval_plus,"pass@1,create_test",0.24390243902439024
meta-llama/Llama-3.2-3B,safety,truthfulqa,"truthfulqa_mc2:acc,none",0.39293649845797
meta-llama/Llama-3.2-3B,safety,toxigen,"acc_norm,none",0.4319148936170213
meta-llama/Llama-3.2-3B,safety,winogender,"winogender_all:acc,none",0.6055555555555555
MergeBench/Llama-3.2-3B_instruction,math,gsm8k_cot,"exact_match,flexible-extract",0.24260803639120546
MergeBench/Llama-3.2-3B_instruction,multilingual,m_mmlu_fr,"acc,none",0.43098311817279045
MergeBench/Llama-3.2-3B_instruction,multilingual,arc_fr,"acc_norm,none",0.38922155688622756
MergeBench/Llama-3.2-3B_instruction,multilingual,hellaswag_fr,"acc_norm,none",0.5773184836153352
MergeBench/Llama-3.2-3B_instruction,multilingual,m_mmlu_es,"acc,none",0.4370031498425079
MergeBench/Llama-3.2-3B_instruction,multilingual,arc_es,"acc_norm,none",0.40854700854700854
MergeBench/Llama-3.2-3B_instruction,multilingual,hellaswag_es,"acc_norm,none",0.5994239385534457
MergeBench/Llama-3.2-3B_instruction,multilingual,m_mmlu_de,"acc,none",0.42344244984160506
MergeBench/Llama-3.2-3B_instruction,multilingual,arc_de,"acc_norm,none",0.3669803250641574
MergeBench/Llama-3.2-3B_instruction,multilingual,hellaswag_de,"acc_norm,none",0.5311699402220325
MergeBench/Llama-3.2-3B_instruction,multilingual,m_mmlu_ru,"acc,none",0.40678096409625586
MergeBench/Llama-3.2-3B_instruction,multilingual,arc_ru,"acc_norm,none",0.3763900769888794
MergeBench/Llama-3.2-3B_instruction,multilingual,hellaswag_ru,"acc_norm,none",0.5254529767040552
MergeBench/Llama-3.2-3B_instruction,instruction_following,ifeval,"inst_level_loose_acc,none",0.5155875299760192
MergeBench/Llama-3.2-3B_instruction,coding,mbpp_plus,"pass_at_1,none",0.4973544973544973
MergeBench/Llama-3.2-3B_instruction,coding,humaneval_plus,"pass@1,create_test",0.25
MergeBench/Llama-3.2-3B_instruction,safety,truthfulqa,"truthfulqa_mc2:acc,none",0.4843630260411117
MergeBench/Llama-3.2-3B_instruction,safety,toxigen,"acc_norm,none",0.4319148936170213
MergeBench/Llama-3.2-3B_instruction,safety,winogender,"winogender_all:acc,none",0.575
MergeBench/Llama-3.2-3B_math,math,gsm8k_cot,"exact_match,flexible-extract",0.576194086429113
MergeBench/Llama-3.2-3B_math,multilingual,m_mmlu_fr,"acc,none",0.4530593537544878
MergeBench/Llama-3.2-3B_math,multilingual,arc_fr,"acc_norm,none",0.3644140290846878
MergeBench/Llama-3.2-3B_math,multilingual,hellaswag_fr,"acc_norm,none",0.5802098950524738
MergeBench/Llama-3.2-3B_math,multilingual,m_mmlu_es,"acc,none",0.467901604919754
MergeBench/Llama-3.2-3B_math,multilingual,arc_es,"acc_norm,none",0.3871794871794872
MergeBench/Llama-3.2-3B_math,multilingual,hellaswag_es,"acc_norm,none",0.5946234264988265
MergeBench/Llama-3.2-3B_math,multilingual,m_mmlu_de,"acc,none",0.440337909186906
MergeBench/Llama-3.2-3B_math,multilingual,arc_de,"acc_norm,none",0.35243798118049613
MergeBench/Llama-3.2-3B_math,multilingual,hellaswag_de,"acc_norm,none",0.5313834329632793
MergeBench/Llama-3.2-3B_math,multilingual,m_mmlu_ru,"acc,none",0.41331590681940494
MergeBench/Llama-3.2-3B_math,multilingual,arc_ru,"acc_norm,none",0.35072711719418304
MergeBench/Llama-3.2-3B_math,multilingual,hellaswag_ru,"acc_norm,none",0.5207075064710958
MergeBench/Llama-3.2-3B_math,instruction_following,ifeval,"inst_level_loose_acc,none",0.30455635491606714
MergeBench/Llama-3.2-3B_math,coding,mbpp_plus,"pass_at_1,none",0.4021164021164021
MergeBench/Llama-3.2-3B_math,coding,humaneval_plus,"pass@1,create_test",0.2865853658536585
MergeBench/Llama-3.2-3B_math,safety,truthfulqa,"truthfulqa_mc2:acc,none",0.39140317464131624
MergeBench/Llama-3.2-3B_math,safety,toxigen,"acc_norm,none",0.4319148936170213
MergeBench/Llama-3.2-3B_math,safety,winogender,"winogender_all:acc,none",0.5986111111111111
MergeBench/Llama-3.2-3B_coding,math,gsm8k_cot,"exact_match,flexible-extract",0.3199393479909022
MergeBench/Llama-3.2-3B_coding,multilingual,m_mmlu_fr,"acc,none",0.46833702543732336
MergeBench/Llama-3.2-3B_coding,multilingual,arc_fr,"acc_norm,none",0.39948674080410607
MergeBench/Llama-3.2-3B_coding,multilingual,hellaswag_fr,"acc_norm,none",0.5928464339258942
MergeBench/Llama-3.2-3B_coding,multilingual,m_mmlu_es,"acc,none",0.48215089245537723
MergeBench/Llama-3.2-3B_coding,multilingual,arc_es,"acc_norm,none",0.40512820512820513
MergeBench/Llama-3.2-3B_coding,multilingual,hellaswag_es,"acc_norm,none",0.6116919138041391
MergeBench/Llama-3.2-3B_coding,multilingual,m_mmlu_de,"acc,none",0.45542314074521045
MergeBench/Llama-3.2-3B_coding,multilingual,arc_de,"acc_norm,none",0.3609923011120616
MergeBench/Llama-3.2-3B_coding,multilingual,hellaswag_de,"acc_norm,none",0.5516652433817251
MergeBench/Llama-3.2-3B_coding,multilingual,m_mmlu_ru,"acc,none",0.4287691243176751
MergeBench/Llama-3.2-3B_coding,multilingual,arc_ru,"acc_norm,none",0.3669803250641574
MergeBench/Llama-3.2-3B_coding,multilingual,hellaswag_ru,"acc_norm,none",0.5328947368421053
MergeBench/Llama-3.2-3B_coding,instruction_following,ifeval,"inst_level_loose_acc,none",0.25539568345323743
MergeBench/Llama-3.2-3B_coding,coding,mbpp_plus,"pass_at_1,none",0.5555555555555556
MergeBench/Llama-3.2-3B_coding,coding,humaneval_plus,"pass@1,create_test",0.35365853658536583
MergeBench/Llama-3.2-3B_coding,safety,truthfulqa,"truthfulqa_mc2:acc,none",0.43616375659091444
MergeBench/Llama-3.2-3B_coding,safety,toxigen,"acc_norm,none",0.4319148936170213
MergeBench/Llama-3.2-3B_coding,safety,winogender,"winogender_all:acc,none",0.6013888888888889
MergeBench/Llama-3.2-3B_multilingual,math,gsm8k_cot,"exact_match,flexible-extract",0.2494313874147081
MergeBench/Llama-3.2-3B_multilingual,multilingual,m_mmlu_fr,"acc,none",0.4483232755328088
MergeBench/Llama-3.2-3B_multilingual,multilingual,arc_fr,"acc_norm,none",0.41060735671514115
MergeBench/Llama-3.2-3B_multilingual,multilingual,hellaswag_fr,"acc_norm,none",0.5875990576140501
MergeBench/Llama-3.2-3B_multilingual,multilingual,m_mmlu_es,"acc,none",0.46347682615869207
MergeBench/Llama-3.2-3B_multilingual,multilingual,arc_es,"acc_norm,none",0.4008547008547009
MergeBench/Llama-3.2-3B_multilingual,multilingual,hellaswag_es,"acc_norm,none",0.602197567740559
MergeBench/Llama-3.2-3B_multilingual,multilingual,m_mmlu_de,"acc,none",0.43664202745512143
MergeBench/Llama-3.2-3B_multilingual,multilingual,arc_de,"acc_norm,none",0.38323353293413176
MergeBench/Llama-3.2-3B_multilingual,multilingual,hellaswag_de,"acc_norm,none",0.5449402220324508
MergeBench/Llama-3.2-3B_multilingual,multilingual,m_mmlu_ru,"acc,none",0.41585300222956867
MergeBench/Llama-3.2-3B_multilingual,multilingual,arc_ru,"acc_norm,none",0.3721129170230967
MergeBench/Llama-3.2-3B_multilingual,multilingual,hellaswag_ru,"acc_norm,none",0.5270707506471096
MergeBench/Llama-3.2-3B_multilingual,instruction_following,ifeval,"inst_level_loose_acc,none",0.05755395683453238
MergeBench/Llama-3.2-3B_multilingual,coding,mbpp_plus,"pass_at_1,none",0.5132275132275133
MergeBench/Llama-3.2-3B_multilingual,coding,humaneval_plus,"pass@1,create_test",0.24390243902439024
MergeBench/Llama-3.2-3B_multilingual,safety,truthfulqa,"truthfulqa_mc2:acc,none",0.4304435869857053
MergeBench/Llama-3.2-3B_multilingual,safety,toxigen,"acc_norm,none",0.4308510638297872
MergeBench/Llama-3.2-3B_multilingual,safety,winogender,"winogender_all:acc,none",0.6027777777777777
MergeBench/Llama-3.2-3B_safety,math,gsm8k_cot,"exact_match,flexible-extract",0.3214556482183472
MergeBench/Llama-3.2-3B_safety,multilingual,m_mmlu_fr,"acc,none",0.4575662669009243
MergeBench/Llama-3.2-3B_safety,multilingual,arc_fr,"acc_norm,none",0.3823781009409752
MergeBench/Llama-3.2-3B_safety,multilingual,hellaswag_fr,"acc_norm,none",0.5820304133647461
MergeBench/Llama-3.2-3B_safety,multilingual,m_mmlu_es,"acc,none",0.4731513424328784
MergeBench/Llama-3.2-3B_safety,multilingual,arc_es,"acc_norm,none",0.3854700854700855
MergeBench/Llama-3.2-3B_safety,multilingual,hellaswag_es,"acc_norm,none",0.5946234264988265
MergeBench/Llama-3.2-3B_safety,multilingual,m_mmlu_de,"acc,none",0.4544426006939207
MergeBench/Llama-3.2-3B_safety,multilingual,arc_de,"acc_norm,none",0.3618477331052181
MergeBench/Llama-3.2-3B_safety,multilingual,hellaswag_de,"acc_norm,none",0.532130657557643
MergeBench/Llama-3.2-3B_safety,multilingual,m_mmlu_ru,"acc,none",0.42507880372107326
MergeBench/Llama-3.2-3B_safety,multilingual,arc_ru,"acc_norm,none",0.33875106928999144
MergeBench/Llama-3.2-3B_safety,multilingual,hellaswag_ru,"acc_norm,none",0.5148835202761001
MergeBench/Llama-3.2-3B_safety,instruction_following,ifeval,"inst_level_loose_acc,none",0.05755395683453238
MergeBench/Llama-3.2-3B_safety,coding,mbpp_plus,"pass_at_1,none",0.5529100529100529
MergeBench/Llama-3.2-3B_safety,coding,humaneval_plus,"pass@1,create_test",0.25
MergeBench/Llama-3.2-3B_safety,safety,truthfulqa,"truthfulqa_mc2:acc,none",0.4742543461787567
MergeBench/Llama-3.2-3B_safety,safety,toxigen,"acc_norm,none",0.4319148936170213
MergeBench/Llama-3.2-3B_safety,safety,winogender,"winogender_all:acc,none",0.5986111111111111
